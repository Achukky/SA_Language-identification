{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0d7330-f0d8-4fda-95f8-a9faa58bfd57",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007cff6-54e7-48f5-93ec-2ef8861d93d7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a href=#three>1. Introduction</a>\n",
    "\n",
    "<a href=#four>2. Problem Statement</a>\n",
    "\n",
    "<a href=#five>3. Aim & Objectives</a>\n",
    "\n",
    "<a href=#six>4. Literature Review</a>\n",
    "\n",
    "<a href=#seven>5. Importing Packages</a>\n",
    "\n",
    "<a href=#eight>6. Loading Data</a>\n",
    "\n",
    "<a href=#nine>7. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#ten>8. Preprocessing</a>\n",
    "\n",
    "<a href=#eleven>9. Modeling and Evaluation</a>\n",
    "\n",
    "<a href=#twelve>10. Analysis and Output</a>\n",
    "\n",
    "<a href=#thirteen>11. Conclusion</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bcfad-7dda-4c10-bd39-d97bf2872dd6",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 1. Introduction\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874229e-b0b0-41ca-8edc-c13a491ad53b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"four\"></a>\n",
    "## 2. Problem Statement \n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "In such multilingual societies, there are several circumstances that may warrant the desire or need to understand text written in a certain strange language. Before any meaningful translation is possible, it is necessary to first identify the language in which the text was written. Automatic language translator systems also need to identify the language of a text before mapping it to the corpora or lexicon of the known language for translation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc7a73-93bd-47ce-b7dd-63794bfecdb6",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 3. Aim & Objectives\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "### Aim\n",
    "- The aim of this project is to accurately classify any text into its appropriate language.\n",
    "\n",
    "### Objectives\n",
    "- Explanatory Data Analysis of the dataset provided.\n",
    "- Data Preprocessing and Feature Engineering.\n",
    "- Applying of different Classification models.\n",
    "- Model Evaluaion and Explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85e6ec-5c91-453f-a013-d983d4df27a2",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 4. Literature Review\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Language identification may be classified under Natural Language Processing which is a subfield of a nunber of areas including Computer Science, Artificial Intelligence and linguistics. Its essentially involved with making computer systems understand human language in voice or text data format in order to provide an accurate intuitive response. NLP combines computational linguistics—rule-based modeling of human language—with statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning, complete with the speaker or writer’s intent and sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75086096-930c-45f9-84c4-1ef89a418089",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 5. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc667d91-a978-445e-9a9d-7397f76198da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basic libraries \n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# imports for Natural Language  Processing\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from html.parser import HTMLParser\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "# Classification Models\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Import library for train test split\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "# Set plot style\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Wordcloud\n",
    "from PIL import Image\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a762d8",
   "metadata": {},
   "source": [
    "<a id=\"eight\"></a>\n",
    "## 6. Loading data \n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220a8212-7f01-477a-9017-a250b801fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_set.csv\") # load train dataset\n",
    "df_test = pd.read_csv(\"test_set.csv\") # load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313ea980-1653-4257-b449-3a6f6be0baa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "0         xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1         xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2         eng  the province of kwazulu-natal department of tr...\n",
       "3         nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "...       ...                                                ...\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "32997     eng  closing date for the submission of completed t...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f2bdd8d-b902-4e7d-8955-43f4d44c8240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>You mark your ballot in private.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>Ge o ka kgetha ka bowena go se šomiše Mofani k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>E Ka kopo etsa kgetho ya hao ka hloko, hobane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>TB ke bokudi ba PMB, mme Morero o tla lefella ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>Vakatjhela iwebhusayidi yethu ku-www.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1         2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2         3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3         4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4         5                      Winste op buitelandse valuta.\n",
       "...     ...                                                ...\n",
       "5677   5678                   You mark your ballot in private.\n",
       "5678   5679  Ge o ka kgetha ka bowena go se šomiše Mofani k...\n",
       "5679   5680  E Ka kopo etsa kgetho ya hao ka hloko, hobane ...\n",
       "5680   5681  TB ke bokudi ba PMB, mme Morero o tla lefella ...\n",
       "5681   5682              Vakatjhela iwebhusayidi yethu ku-www.\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ec62e",
   "metadata": {},
   "source": [
    "<a id=\"nine\"></a>\n",
    "## 7. Exploratory Data Analysis\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d18f281b-48e8-4acd-bbf9-ae9101a526b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 2)\n",
      "(5682, 2)\n"
     ]
    }
   ],
   "source": [
    "# explore shape of data\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b173670-260c-47dd-852a-966062f9ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.25 %\n"
     ]
    }
   ],
   "source": [
    "# Looking for duplicates\n",
    "percent_duplicates = round((1-(df_train['text'].nunique()/len(df_train['text'])))*100,2)\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f9b4cf2-6f18-40e5-a562-74b9fb4dc6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    29948\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop_duplicates(subset=\"text\",keep=\"first\",inplace=True,ignore_index=True) #remove duplicate entries from test data\n",
    "df_train.text.duplicated(keep=\"first\").value_counts() #confirm removal of duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10bcc860-b95d-4f5a-b88a-8f399c303027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29948</td>\n",
       "      <td>29948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>29948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>eng</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lang_id                                               text\n",
       "count    29948                                              29948\n",
       "unique      11                                              29948\n",
       "top        eng  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "freq      2998                                                  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore summary statistics for dataset\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f17f62-43a0-4b92-93a2-229470f3eba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for unique values for language id\n",
    "langs = df_train['lang_id'].unique() \n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44570dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng    2998\n",
       "zul    2924\n",
       "nso    2873\n",
       "tsn    2869\n",
       "sot    2833\n",
       "tso    2758\n",
       "xho    2659\n",
       "afr    2641\n",
       "ven    2605\n",
       "ssw    2426\n",
       "nbl    2362\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for unique value count for the target variable\n",
    "df_train['lang_id'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db805b7",
   "metadata": {},
   "source": [
    "<a id=\"ten\"></a>\n",
    "## 8. Preprocessing\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2e62ef-c18f-4017-b645-cb2f237709ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(df):\n",
    "    \"\"\"\n",
    "    function that takes a dataframe that contains text data and returns same dataframe with \n",
    "    \n",
    "    additional columns which respectively contains tokenised and lemmatised versions of the \n",
    "    \n",
    "    texts\n",
    "    \"\"\" \n",
    "    df['tokens'] = df['text'].apply(word_tokenize)\n",
    "    \n",
    "    ### commence Part-of-Speech tagging    \n",
    "    df['pos_tags'] = df['tokens'].apply(nltk.tag.pos_tag)\n",
    "\n",
    "    def get_wordnet_pos(tag):\n",
    "\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "        \n",
    "    # create lemmatizer object    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    df['pos_tags'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "    df['lemmatized'] = df['pos_tags'].apply(lambda x: [lemmatizer.lemmatize(word, tag) for word, tag in x])\n",
    "    df['lemmatized'] = [' '.join(map(str, l)) for l in df['lemmatized']] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d690eae-de5b-46e0-9b21-68d02df29779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguish features and target variables\n",
    "X = df_train[\"text\"]\n",
    "y = df_train[\"lang_id\"]\n",
    "\n",
    "# Create train and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490a5e4",
   "metadata": {},
   "source": [
    "<a id=\"eleven\"></a>\n",
    "## 9. Modelling and Evaluation\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0785c2d5-bde1-4a70-879e-3172582f30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(models, X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    results = []\n",
    "    names = []\n",
    "    target_names = ['xho', 'eng', 'nso', 'ven','tsn', 'nbl', 'zul', 'ssw','tso', 'sot', 'afr']\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=50) # splitting the data into kfolds\n",
    "        cv_results = cross_validate(model, X_train, y_train, cv=kfold)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b39bb0e-bbf7-41a4-9e15-f39a049284a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model using count vectorizer \n",
    "model_base = [\n",
    "        ('LogReg', Pipeline([('Count',CountVectorizer()),('classify', LogisticRegression())])), \n",
    "        ('RF', Pipeline([('Count',CountVectorizer()),('classify', RandomForestClassifier())])),\n",
    "        ('KNN', Pipeline([('Count',CountVectorizer()),('classify', KNeighborsClassifier())])),\n",
    "        ('MULT', Pipeline([('Count',CountVectorizer()),('classify',MultinomialNB())])),        \n",
    "        ('LINSVM', Pipeline([('Count',CountVectorizer()),('classify', LinearSVC())]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d94bb395-90d6-4e81-bea6-da523edcf3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         xho       1.00      1.00      1.00       879\n",
      "         eng       1.00      1.00      1.00      1008\n",
      "         nso       0.98      0.98      0.98       757\n",
      "         ven       1.00      1.00      1.00       930\n",
      "         tsn       1.00      1.00      1.00       941\n",
      "         nbl       0.99      0.99      0.99       824\n",
      "         zul       1.00      1.00      1.00       928\n",
      "         ssw       1.00      1.00      1.00       894\n",
      "         tso       1.00      1.00      1.00       859\n",
      "         sot       0.99      0.99      0.99       864\n",
      "         afr       0.98      0.97      0.98       999\n",
      "\n",
      "    accuracy                           0.99      9883\n",
      "   macro avg       0.99      0.99      0.99      9883\n",
      "weighted avg       0.99      0.99      0.99      9883\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         xho       1.00      1.00      1.00       879\n",
      "         eng       0.99      1.00      1.00      1008\n",
      "         nso       0.98      0.91      0.94       757\n",
      "         ven       1.00      1.00      1.00       930\n",
      "         tsn       1.00      1.00      1.00       941\n",
      "         nbl       0.99      0.94      0.97       824\n",
      "         zul       1.00      1.00      1.00       928\n",
      "         ssw       1.00      1.00      1.00       894\n",
      "         tso       1.00      1.00      1.00       859\n",
      "         sot       0.96      0.97      0.97       864\n",
      "         afr       0.90      0.96      0.93       999\n",
      "\n",
      "    accuracy                           0.98      9883\n",
      "   macro avg       0.98      0.98      0.98      9883\n",
      "weighted avg       0.98      0.98      0.98      9883\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         xho       1.00      0.99      1.00       879\n",
      "         eng       1.00      0.99      1.00      1008\n",
      "         nso       0.63      0.89      0.74       757\n",
      "         ven       0.93      0.90      0.92       930\n",
      "         tsn       0.99      0.95      0.97       941\n",
      "         nbl       0.91      0.84      0.87       824\n",
      "         zul       0.89      0.93      0.91       928\n",
      "         ssw       1.00      0.98      0.99       894\n",
      "         tso       0.99      0.99      0.99       859\n",
      "         sot       0.88      0.77      0.82       864\n",
      "         afr       0.85      0.77      0.81       999\n",
      "\n",
      "    accuracy                           0.91      9883\n",
      "   macro avg       0.92      0.91      0.91      9883\n",
      "weighted avg       0.92      0.91      0.91      9883\n",
      "\n",
      "MULT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         xho       1.00      1.00      1.00       879\n",
      "         eng       0.99      1.00      1.00      1008\n",
      "         nso       1.00      1.00      1.00       757\n",
      "         ven       1.00      1.00      1.00       930\n",
      "         tsn       1.00      1.00      1.00       941\n",
      "         nbl       1.00      1.00      1.00       824\n",
      "         zul       1.00      1.00      1.00       928\n",
      "         ssw       1.00      1.00      1.00       894\n",
      "         tso       1.00      1.00      1.00       859\n",
      "         sot       1.00      1.00      1.00       864\n",
      "         afr       1.00      0.99      0.99       999\n",
      "\n",
      "    accuracy                           1.00      9883\n",
      "   macro avg       1.00      1.00      1.00      9883\n",
      "weighted avg       1.00      1.00      1.00      9883\n",
      "\n",
      "LINSVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         xho       1.00      1.00      1.00       879\n",
      "         eng       1.00      1.00      1.00      1008\n",
      "         nso       0.98      0.98      0.98       757\n",
      "         ven       1.00      1.00      1.00       930\n",
      "         tsn       1.00      1.00      1.00       941\n",
      "         nbl       1.00      0.99      0.99       824\n",
      "         zul       1.00      1.00      1.00       928\n",
      "         ssw       1.00      1.00      1.00       894\n",
      "         tso       1.00      1.00      1.00       859\n",
      "         sot       0.99      0.99      0.99       864\n",
      "         afr       0.98      0.98      0.98       999\n",
      "\n",
      "    accuracy                           1.00      9883\n",
      "   macro avg       1.00      1.00      1.00      9883\n",
      "weighted avg       1.00      1.00      1.00      9883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelled = model(model_base, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ec7a8",
   "metadata": {},
   "source": [
    "<a id=\"twelve\"></a>\n",
    "## 10. Analysis and Output\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d79b2-c5b4-4f21-800e-fbcdbb7bb74d",
   "metadata": {},
   "source": [
    "From the foregoing results of the cross validation of the models used, it is clear that the best performing models are the Multinomial Naive Bayes and the Linear Support Vector Machine. However, the Multinomial Naive Bayes just about does enough to edge the Support Vector Machine model when comparing their f1-score as well as their respective accuracies.\n",
    "\n",
    "Consequently, the whole training data will be used to fit the multinomial NB model except this time, a TFidf Vectoriser will be used in place of the Count Vectoriser and then the trained model will be used to predict the outcome of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "852af187-1b8c-445f-ad22-9e11a5482841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes\n",
    "multi = Pipeline([('tfidf', TfidfVectorizer(sublinear_tf=True, \n",
    "                                            smooth_idf = True, \n",
    "                                            max_df = 0.2,\n",
    "                                            ngram_range = (1, 5),\n",
    "                                            stop_words='english')),\n",
    "                  ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a7cc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#('MULT', Pipeline([('Count',CountVectorizer()),('classify',MultinomialNB())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68b177bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.2, ngram_range=(1, 5),\n",
       "                                 stop_words='english', sublinear_tf=True)),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84f46201-d1e8-418d-950c-9265600ea79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>nso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>tso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang_id\n",
       "0        tsn\n",
       "1        nbl\n",
       "2        ven\n",
       "3        ssw\n",
       "4        afr\n",
       "...      ...\n",
       "5677     eng\n",
       "5678     nso\n",
       "5679     sot\n",
       "5680     sot\n",
       "5681     tso\n",
       "\n",
       "[5682 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set test data object for predictions\n",
    "X_test = df_test['text']\n",
    "predictions = multi.predict(X_test)\n",
    "result_df = pd.DataFrame(predictions, columns=['lang_id'])\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b51051c-849a-4762-92a5-729915a1922f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>nso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>tso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index lang_id\n",
       "0         1     tsn\n",
       "1         2     nbl\n",
       "2         3     ven\n",
       "3         4     ssw\n",
       "4         5     afr\n",
       "...     ...     ...\n",
       "5677   5678     eng\n",
       "5678   5679     nso\n",
       "5679   5680     sot\n",
       "5680   5681     sot\n",
       "5681   5682     tso\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare required output data file\n",
    "output = pd.DataFrame({\"index\":df_test['index']})\n",
    "submission = output.join(result_df)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7503f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the submission file in csv format\n",
    "submission.to_csv(\"Joseph_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc694b",
   "metadata": {},
   "source": [
    "<a id=\"thirteen\"></a>\n",
    "## 11. Conclusion\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3733e17",
   "metadata": {},
   "source": [
    "In this project a model has been created to identify to a high extent of accuracy, the language any South African text is written in. A number of models were tested and the MultiNomial Naive Bayes model was the best performing model and hence was used to train the whole train data."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b683bd4b87c8b16609ac9a3ef3aab015b96a8503b853fa71d3fe1e7ebcd29d95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
